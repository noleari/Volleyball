{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id = {}\n",
    "with open(\"team_id.csv\", \"r\") as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        team, id = line.split(\",\")\n",
    "        team_id[int(id.strip())] = team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to add rolling average columns to dataframe\n",
    "\n",
    "def rolling_avgs(df, cols, new_cols):\n",
    "    for col, new_col in zip(cols, new_cols):\n",
    "        df[new_col + \"_3\"] = df[col].rolling(3, closed=\"left\").mean()\n",
    "        df[\"cumsum\"] = df[col].cumsum()\n",
    "        df[\"index_val\"] = range(1, len(df) + 1)\n",
    "        df[new_col + \"_total\"] = df[\"cumsum\"].shift(1).fillna(0) / df[\"index_val\"]\n",
    "        df.drop([\"cumsum\", \"index_val\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"kills/set\", \"errors/set\", \"total_attacks/set\", \"hit_pct\", \"assists/set\", \"aces/set\", \"serr/set\", \"digs/set\", \"b_solo/set\", \"b_assist/set\", \"b_error/set\", \"pts/set\"]\n",
    "new_cols = [f\"rolling_{c}\" for c in cols]\n",
    "\n",
    "for root, dirs, filenames in os.walk(\"all_schedules\"):\n",
    "    for filename in fnmatch.filter(filenames, \"*.csv\"):\n",
    "        df = pd.read_csv(os.path.join(root, filename), delimiter=\",\")\n",
    "        rolling_avgs(df, cols, new_cols)\n",
    "        df.to_csv(os.path.join(root, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = []\n",
    "for key, l in games.items():\n",
    "    if len(l) != 2:\n",
    "        bad.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate opponent and venue\n",
    "\n",
    "def seperate_opp_venue(x):\n",
    "    opp_ven = x[\"opponent/venue\"]\n",
    "    res = \"\"\n",
    "    if \"@\" not in opp_ven:\n",
    "        res = opp_ven.strip()\n",
    "    elif opp_ven.startswith(\"@\"):\n",
    "        res =  opp_ven.split(\"@\")[-1].strip()\n",
    "    else:\n",
    "        res = opp_ven.split(\"@\")[0].strip()\n",
    "    return res.split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some set data was impossible/incorrect, extract sets from result seems reliable\n",
    "def sets_from_result(x):\n",
    "    return sum([int(val.strip()) for val in x[\"result\"].split(\"-\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"kills\", \"errors\", \"total_attacks\", \"assists\", \"aces\", \"serr\", \"digs\", \"b_solo\", \"b_assist\", \"b_error\", \"pts\"]\n",
    "new_cols = [f\"{c}/set\" for c in cols]\n",
    "\n",
    "\n",
    "for root, dirs, filenames in os.walk(\"all_schedules\"):\n",
    "    for filename in fnmatch.filter(filenames, \"*.csv\"):\n",
    "        df = pd.read_csv(os.path.join(root, filename), delimiter=\",\")\n",
    "        df[\"sets_from_result\"] = df.apply(lambda x: sum([int(val.strip()) for val in x[\"result\"].split(\"-\")]), 1)\n",
    "        for col, new_col in zip(cols, new_cols):\n",
    "            df[new_col] = df.apply(lambda x: x[col] / x[\"sets_from_result\"], 1)\n",
    "        df.to_csv(os.path.join(root, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
